trainer: 
  accelerator: 'gpu'
  devices: 1
  reload_dataloaders_every_n_epochs: 1
  max_epochs: -1
  log_every_n_steps: 46
  deterministic: True
  max_epochs: 30
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args: 
      project: GLOM
      dir: ''
      log_model: All
  callbacks: 
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args: 
        monitor: val/recon_loss
        mode: min
        save_top_k: 1
        dirpath: ckpt/    
model:
  image_shape:
    - 1
    - 28
    - 28
  num_patch_side: 7
  hidden_dim: 20
  levels: 2
  iters: 4
  contributions: 
    - 0.15 # wl
    - 0.30 # wBU
    - 0.25 # wTD
    - 0.30 # wA
  optimizer_args: 
    lr: 0.05
    decay: 0.0005
    steps_per_epoch: 46
    epochs: 30
  location_embedding: True
  add_embedding: False
  encoder: 'patch'
  decoder: 'patch'
data:
  data_dir: datasets
  batch_size: 1024